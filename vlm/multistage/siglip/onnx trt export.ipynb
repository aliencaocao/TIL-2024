{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T06:23:47.981367Z",
     "start_time": "2024-06-08T06:23:38.675371Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForZeroShotImageClassification, AutoTokenizer, ZeroShotImageClassificationPipeline, SiglipProcessor\n",
    "from modeling_siglip import SiglipModel\n",
    "from torch2trt import torch2trt\n",
    "\n",
    "model = SiglipModel.from_pretrained('siglip-large-epoch5-augv2-upscale_0.892_cont_5ep_0.905', torch_dtype=torch.float16).cuda()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T06:23:47.996367Z",
     "start_time": "2024-06-08T06:23:47.982369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_model = model.text_model\n",
    "vision_model = model.vision_model"
   ],
   "id": "2f651c7aa11b2f2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T06:00:04.119192Z",
     "start_time": "2024-06-08T06:00:04.068051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy = torch.ones(1, 3, 384, 384, dtype=torch.float16, device='cuda')\n",
    "vision_model(dummy)"
   ],
   "id": "a9001d7106bdbda6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 2.9453, -0.6533,  0.4304,  ...,  0.6572, -0.6221, -1.0801],\n",
       "         [-2.0645, -0.8403, -1.4346,  ..., -1.4717, -0.5347, -0.4978],\n",
       "         [-0.4597, -0.1000, -1.9961,  ..., -1.2549, -1.2227, -0.5923],\n",
       "         ...,\n",
       "         [-1.4844, -0.2078,  0.4170,  ...,  0.6338, -0.3677, -0.3564],\n",
       "         [ 1.7197, -1.0742,  0.5806,  ...,  1.1084,  0.3052, -0.2898],\n",
       "         [ 1.5098, -0.5830,  0.6035,  ..., -1.5576, -1.0205, -0.1233]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.1611,  0.6851, -0.2966,  ...,  0.6460,  0.0237,  0.5977]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_trt = torch2trt(vision_model, [dummy], fp16_mode=True, min_shapes=[(1, 3, 384, 384)], opt_shapes=[(4, 3, 384, 384)], max_shapes=[(10, 3, 384, 384)], use_onnx=True)",
   "id": "276128ce5aeb555d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T05:17:20.097469Z",
     "start_time": "2024-06-08T05:17:20.056597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = vision_model(dummy).pooler_output\n",
    "y_trt = model_trt(dummy)['pooler_output']\n",
    "print(torch.max(torch.abs(y - y_trt)))"
   ],
   "id": "376590ea97370233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0156, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T05:19:22.665695Z",
     "start_time": "2024-06-08T05:19:18.112622Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model_trt.state_dict(), 'vision_trt.pth')",
   "id": "7e3487582894d1d5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T05:19:58.482343Z",
     "start_time": "2024-06-08T05:19:55.020317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch2trt import TRTModule\n",
    "import torch\n",
    "\n",
    "model_trt = TRTModule()\n",
    "\n",
    "model_trt.load_state_dict(torch.load('vision_trt.pth'))"
   ],
   "id": "9e1c0aec861ea9aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T06:23:48.232367Z",
     "start_time": "2024-06-08T06:23:47.997368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy = torch.ones(1, 64, dtype=torch.long, device='cuda')\n",
    "text_model(dummy)"
   ],
   "id": "746ceb1835331288",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "attention_mask None\n",
      "position_ids None\n",
      "output_attentions None\n",
      "output_hidden_states None\n",
      "return_dict None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.2983, -0.0971, -0.3064,  ...,  0.0174, -0.1897, -0.2632],\n",
       "         [-0.2986, -0.1025, -0.3005,  ...,  0.0073, -0.1958, -0.2559],\n",
       "         [ 0.3943, -0.1912,  0.0609,  ..., -1.0537, -0.3950, -0.9185],\n",
       "         ...,\n",
       "         [-0.6899, -0.2805,  0.0827,  ..., -0.5435, -0.0458, -0.5972],\n",
       "         [-0.3210, -0.5361,  0.6953,  ..., -0.3293,  0.3630, -0.8301],\n",
       "         [-0.9072, -1.2393,  0.5645,  ..., -1.2764, -0.6094, -0.6641]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0044,  0.5698, -0.6294,  ...,  1.7988, -0.3899, -0.4961]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_trt = torch2trt(text_model, [dummy], fp16_mode=True, min_shapes=[(1, 64)], opt_shapes=[(1, 64)], max_shapes=[(1, 64)], use_onnx=True)",
   "id": "481777bf15f48e08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T06:02:13.672340Z",
     "start_time": "2024-06-08T06:02:13.629241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = text_model(dummy).pooler_output\n",
    "y_trt = model_trt(dummy)['pooler_output']\n",
    "print(torch.max(torch.abs(y - y_trt)))"
   ],
   "id": "53ee3ba8b577955e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "attention_mask None\n",
      "position_ids None\n",
      "output_attentions None\n",
      "output_hidden_states None\n",
      "return_dict None\n",
      "tensor(0.0156, device='cuda:0', dtype=torch.float16, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T06:02:33.306763Z",
     "start_time": "2024-06-08T06:02:33.293124Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model_trt.state_dict(), 'text_trt.pth')",
   "id": "873e74a4326b816c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T16:48:33.386429Z",
     "start_time": "2024-06-06T16:48:20.391099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.onnx.export(\n",
    "      vision_model,\n",
    "      torch.ones(1, 3, 384, 384, dtype=torch.float32),\n",
    "      \"vision.onnx\",\n",
    "      opset_version=17,\n",
    "      input_names=[\"input\"],\n",
    "      output_names=[\"output\"],\n",
    "      dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    ")"
   ],
   "id": "93c5b8915685d1d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\models\\siglip\\modeling_siglip.py:308: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if interpolate_pos_encoding:\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\models\\siglip\\modeling_siglip.py:393: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (batch_size, self.num_heads, q_len, k_v_seq_len):\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\models\\siglip\\modeling_siglip.py:411: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (batch_size, self.num_heads, q_len, self.head_dim):\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T16:48:43.227422Z",
     "start_time": "2024-06-06T16:48:33.387429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.onnx.export(\n",
    "      text_model,\n",
    "      torch.zeros(1, 64, dtype=torch.int64),\n",
    "      \"text.onnx\",\n",
    "      opset_version=17,\n",
    "      input_names=[\"input\"],\n",
    "      output_names=[\"output\"],\n",
    "      dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    ")"
   ],
   "id": "77279ee7a5e263f6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!trtexec --onnx=vision.onnx --saveEngine=vision.engine --minShapes=input:1x3x384x384 --maxShapes=input:10x3x384x384 --optShapes=input:4x3x384x384 --memPoolSize=workspace:8000 --fp16\n",
    "!trtexec --onnx=text.onnx --saveEngine=text.engine --minShapes=input:1x64 --maxShapes=input:1x64 --optShapes=input:1x64 --memPoolSize=workspace:8000 --fp16"
   ],
   "id": "b82945cc3420737c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
